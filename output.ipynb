{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 75, 64, 64, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = np.load('full_videos_read.npy')\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 75, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "new_frames = []\n",
    "for i in frames:  # Loop over videos\n",
    "    frame = []\n",
    "    for j in i:  # Loop over frames\n",
    "        frame.append(cv2.cvtColor(j, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    new_frames.append(np.asarray(frame))\n",
    "\n",
    "new_frames = np.asarray(new_frames)\n",
    "print(new_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 75, 64, 64, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_frames = np.expand_dims(new_frames, axis = -1)\n",
    "new_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/g/projects/lip_reading_project/data/alignments/s1/*'\n",
    "texts = []\n",
    "for i in glob.glob(path):\n",
    "    with open(file = i,mode='r') as f:\n",
    "        texts.append(f.read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "start = []\n",
    "end   = []\n",
    "\n",
    "for text in texts:\n",
    "    start.append(text[0::3])\n",
    "    end.append(text[1::3])\n",
    "    words.append(text[2::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['sil', 'bin', 'blue', 'at', 'f', 'three', 'soon', 'sil'],\n",
       " ['0', '17750', '22500', '27000', '28000', '31000', '36250', '46750'],\n",
       " ['17750', '22500', '27000', '28000', '31000', '36250', '46750', '74500'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[1], start[1],end[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_word_sequences(word_lists, max_words=54, max_vocabulary=100, max_frames=9):\n",
    "    # Flatten the list of word lists into a single list for tokenization\n",
    "    all_words = [word for sublist in word_lists for word in sublist]\n",
    "    \n",
    "    # Create Tokenizer\n",
    "    tokenizer = Tokenizer(num_words=max_vocabulary, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(all_words)\n",
    "    \n",
    "    # Convert words to sequences of indices\n",
    "    encoded_sequences = tokenizer.texts_to_sequences(word_lists)\n",
    "    \n",
    "    # Pad each sequence to ensure it has exactly `max_words` (54) per time step\n",
    "    padded_sequences = pad_sequences(\n",
    "        encoded_sequences, \n",
    "        maxlen=max_words,  # Each time step should have 54 words\n",
    "        padding='post',  # Add zeros at the end\n",
    "        truncating='post'  # Truncate from the end if too long\n",
    "    )\n",
    "    \n",
    "    # Pad the entire sequence to ensure there are `max_frames` (9) time steps for each video\n",
    "    padded_sequences = pad_sequences(\n",
    "        padded_sequences, \n",
    "        maxlen=max_frames,  # Ensure there are 9 time steps\n",
    "        padding='post',  # Add zeros at the end if fewer than 9 time steps\n",
    "        truncating='post'  # Truncate from the end if more than 9 time steps\n",
    "    )\n",
    "    \n",
    "    words_test_new =[]\n",
    "    for line in padded_sequences:\n",
    "        words_test_new.append(tf.keras.utils.to_categorical(x = line, num_classes=55))\n",
    "    \n",
    "    return {\n",
    "        'padded_sequences': np.asarray(words_test_new),\n",
    "        'tokenizer': tokenizer,\n",
    "        'word_index': tokenizer.word_index\n",
    "    }\n",
    "    \n",
    "    \n",
    "result = prepare_word_sequences(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9, 55)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"padded_sequences\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sequence, max_length):\n",
    "    # Pad with zeros (or other value) if the sequence is shorter than max_length\n",
    "    if len(sequence) < max_length:\n",
    "        return np.pad(sequence, (0, max_length - len(sequence)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        return sequence[:max_length]  # Truncate if the sequence is longer than max_length\n",
    "\n",
    "# Set the fixed length you want (9 elements)\n",
    "max_length = 9\n",
    "\n",
    "# Pad the sequences in `start` (assuming `start` is a list of sequences with varying lengths)\n",
    "start_padded = np.array([pad_sequence(s, max_length) for s in start])\n",
    "\n",
    "# Similarly, pad the sequences in `end` if needed\n",
    "end_padded = np.array([pad_sequence(e, max_length) for e in end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 75, 64, 64, 1), (1000, 9, 55), (1000, 9), (1000, 9))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_frames.shape, result[\"padded_sequences\"].shape, start_padded.shape, end_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_padded = start_padded.astype(np.int32)\n",
    "end_padded = end_padded.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_padded = start_padded / 74500\n",
    "start_padded = np.asarray(start_padded, dtype=np.float32)\n",
    "\n",
    "\n",
    "end_padded = end_padded / 74500\n",
    "end_padded = np.asarray(end_padded, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj):\n",
    "\n",
    "    # 1x1 convolution branch\n",
    "    branch1 = keras.layers.Conv3D(filters_1x1, (1,1,1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # 3x3 convolution branch\n",
    "    branch2 = keras.layers.Conv3D(filters_3x3_reduce, (1,1,1), padding='same', activation='relu')(x)\n",
    "    branch2 = keras.layers.Conv3D(filters_3x3, (3,3,3), padding='same', activation='relu')(branch2)\n",
    "    \n",
    "    # 5x5 convolution branch\n",
    "    branch3 = keras.layers.Conv3D(filters_5x5_reduce, (1,1,1), padding='same', activation='relu')(x)\n",
    "    branch3 = keras.layers.Conv3D(filters_5x5, (5,5,5), padding='same', activation='relu')(branch3)\n",
    "    \n",
    "    # Pool projection branch\n",
    "    branch4 = keras.layers.MaxPooling3D((3,3,3), strides=(1,1,1), padding='same')(x)\n",
    "    branch4 = keras.layers.Conv3D(filters_pool_proj, (1,1,1), padding='same', activation='relu')(branch4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(branch1.shape)\n",
    "    # print(branch2.shape)\n",
    "    # print(branch3.shape)\n",
    "    # print(branch4.shape)\n",
    "    # print('_____________')\n",
    "    \n",
    "    \n",
    "    # Concatenate all branches\n",
    "    return keras.layers.Concatenate()([branch1, branch2, branch3, branch4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('google_net_full_video(1).h5', custom_objects={\n",
    "        'inception_module': inception_module,\n",
    "        'mse': tf.keras.losses.MeanSquaredError()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 19:03:25.044814: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1228800000 exceeds 10% of free system memory.\n",
      "2024-12-13 19:03:25.906858: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1228800000 exceeds 10% of free system memory.\n",
      "2024-12-13 19:03:28.474322: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "W0000 00:00:1734109408.722718   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109408.989212   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.202514   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.206058   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.208293   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.231968   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.234869   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.238978   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.242253   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.277522   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.279616   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.281020   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.282482   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.284692   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.286291   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.288235   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.324513   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.333811   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.336267   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.338163   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.340591   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.342648   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.345440   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.347534   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.357432   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.423555   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.512543   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.596877   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.707944   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.815809   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.886257   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.946455   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.950039   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.953530   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.957622   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.961621   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-12-13 19:03:29.966903: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.71GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1734109409.969984   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.972972   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.975998   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.978157   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.981678   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109409.984993   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-12-13 19:03:29.988387: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1734109410.034932   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.037240   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.038966   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.040710   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.042690   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.044549   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.051200   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.069311   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.071646   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.073677   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.075809   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.079107   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.081614   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.085083   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.118135   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.129150   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.142668   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.163762   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.180389   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.206168   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.216523   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.220463   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109410.224775   96794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - end_time_output_loss: 10.1247 - end_time_output_mean_absolute_error: 0.5507 - loss: 10.1320 - start_time_output_loss: 0.0022 - start_time_output_mean_absolute_error: 0.0404 - word_output_accuracy: 0.4542 - word_output_loss: 0.0052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1734109421.414186   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.427684   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.440638   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.451001   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.452621   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.454113   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.455819   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.457337   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.458839   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.467532   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.468956   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.470374   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.471746   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.473096   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.474494   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.475927   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.479222   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.484290   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.485815   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.487035   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.488391   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.489703   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.491081   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.492374   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.496639   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.502379   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.519549   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.540385   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.594471   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.621483   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.659148   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.698346   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.709864   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.723925   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.744098   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.759792   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.761718   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.763264   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.764797   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.766473   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.768882   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-12-13 19:03:41.788794: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1734109421.790514   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.792369   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.793875   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.795178   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.796523   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.798232   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.799808   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-12-13 19:03:41.810383: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.71GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1734109421.812207   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.813608   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.814893   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.816714   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.818060   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.819350   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.821820   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.831653   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.833015   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.834616   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.836108   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.837429   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.838865   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.840392   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.846644   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.870315   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.874017   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.878414   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.884693   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.889673   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.907534   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.910376   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.911976   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.914410   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734109421.916536   96796 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 350ms/step - end_time_output_loss: 10.1148 - end_time_output_mean_absolute_error: 0.5510 - loss: 10.1199 - start_time_output_loss: 0.0022 - start_time_output_mean_absolute_error: 0.0404 - word_output_accuracy: 0.4542 - word_output_loss: 0.0052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.932774543762207,\n",
       " 0.0053385403007268906,\n",
       " 0.0021728086285293102,\n",
       " 9.96225357055664,\n",
       " 0.5554441809654236,\n",
       " 0.04060196131467819,\n",
       " 0.45333331823349]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.evaluate(new_frames, [result[\"padded_sequences\"], start_padded, end_padded] )\n",
    "\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 330ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[0.        , 0.        , 0.9544962 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.9452368 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.9289584 , 0.        , 0.01164295, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.        , 0.9501702 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.9407499 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.9243486 , 0.        , 0.01159385, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.        , 0.9407601 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.9309607 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.9149094 , 0.        , 0.011417  , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.        , 0.        , 0.9346797 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.92585695, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.9100062 , 0.        , 0.01148677, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.        , 0.9456013 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.94063914, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.9248601 , 0.        , 0.01217718, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.        , 0.94701976, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.9427366 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.9268266 , 0.        , 0.0122738 , ..., 0.        ,\n",
       "          0.        , 0.        ]]], dtype=float32),\n",
       " array([[0.0111043 , 0.19207971, 0.29415822, ..., 0.5639604 , 0.67770576,\n",
       "         0.02360147],\n",
       "        [0.01110433, 0.19207983, 0.29415843, ..., 0.5639603 , 0.67770535,\n",
       "         0.02360161],\n",
       "        [0.01110439, 0.19208017, 0.29415902, ..., 0.56396025, 0.6777042 ,\n",
       "         0.02360196],\n",
       "        ...,\n",
       "        [0.01110445, 0.19208048, 0.2941596 , ..., 0.5639601 , 0.6777033 ,\n",
       "         0.02360224],\n",
       "        [0.01110441, 0.19208029, 0.29415926, ..., 0.56395984, 0.67770404,\n",
       "         0.02360196],\n",
       "        [0.01110439, 0.1920802 , 0.29415923, ..., 0.5639598 , 0.67770416,\n",
       "         0.02360186]], dtype=float32),\n",
       " array([[1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "         0.98725104],\n",
       "        [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "         0.98725104],\n",
       "        [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "         0.98725104],\n",
       "        ...,\n",
       "        [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "         0.98725104],\n",
       "        [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "         0.98725104],\n",
       "        [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "         0.98725104]], dtype=float32)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(new_frames)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 9, 55), (1000, 9), (1000, 9))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0].shape,y_pred[1].shape,y_pred[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0111043 , 0.19207971, 0.29415822, 0.37194118, 0.41160592,\n",
       "       0.47448584, 0.5639604 , 0.67770576, 0.02360147], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = []\n",
    "for true, pred in zip(start_padded, y_pred[1]):\n",
    "    m.append(true*75000 - pred*75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-832.82661655, -481.42044637,   62.08574418,  -31.52758218,\n",
       "        -33.53876844, -313.77729625, -299.76973459,   28.17348316,\n",
       "       -480.52893388])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(m, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0, 13924, 22123, 27864, 30836, 35272, 41997, 50856,  1289],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray((y_pred[1][0]*75000 )+ np.mean(m, axis=0), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  832.82261621, 14405.97809851, 22061.86652184, 27895.58842778,\n",
       "       30870.44432759, 35586.43832803, 42297.02800512, 50827.93235779,\n",
       "        1770.11014894])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1][0]*75000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        , 23909.39667821, 29697.98594713, 34228.18779945,\n",
       "       35738.25582862, 41275.16895533, 47567.11274385, 53355.70424795,\n",
       "           0.        ])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_padded[0]*75000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-937.2746804729104"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1][3][0]*75000 - y_pred[1][3][-1]*75000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tokenizer.pkl', 'wb') as f:\n",
    "#     pickle.dump(result['tokenizer'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    loaded_tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('word_index.pkl', 'wb') as f:\n",
    "#     pickle.dump(result['word_index'], f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_index.pkl', 'rb') as f:\n",
    "    loaded_word_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
